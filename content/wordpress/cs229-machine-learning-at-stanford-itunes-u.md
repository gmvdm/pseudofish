Title: CS229 Machine Learning at Stanford (iTunes U)
Date: 2011-07-29 02:40
Author: gmwils
Category: Technology

Andrew Ng's course at Stanford on [Machine Learning][] provides a great
overview of the different types and applications of current machine
learning algorithms. The course is available for free either on
[YouTube][] or subscribe in [iTunes University][].

Be warned, this is a course on theory, so is taught through mathematics
rather than programming. You will develop a deeper understanding, but it
may hurt your brain.

The [section notes][] provide some assistance in reviewing the key
concepts that you'll need.

I've watched the course, but I keep forgetting which lesson covered
which topic. To remember, I've put together a brief summary below:

-   1 — Introduction and overview.
-   2 — [Linear regression][], [Gradient Descent][], and [Normal
    Equations][].
-   3 — Linear regression & probabilistic interpretation, logistic
    regression (classification algorithm), [Newton's method][] and a
    brief introduction to the [Perceptron][] algorithm.
-   4 — [Logistic regression][] & Newton's method, [Exponential
    Family][], [Generalised Linear Models][] (GLMs).
-   5 — Generative learning algorithms, [Gaussian Discriminate
    Analysis][] (GDA), Generative vs Discriminate algorithms, [Naive
    Bayes][], and [Laplace Smoothing][].
-   6 — Naive Bayes & Event Models, [Neural Networks][], [Support Vector
    Machines][] (SVMs).
-   7 — Optimal Margin Classifier, Primal/Dual optimisation problem
    (KKT), SVM dual, [Kernels][].
-   8 — SVMs (Kernels, [Soft Margin][], SMO algorithm)
-   9 — Learning theory: Bias/Variance, [Empirical Risk Minimisation][]
    (ERM), Union Bound/[Hoeffding inequality][], [Uniform
    Convergence][].
-   10 — VC dimension, Model selection (cross validation, feature
    selection), Bayesian statistics & regularisation.
-   11 — Bayesian statistics & regularisation, Online Learning, Advice
    for applying ML algorithms.
-   12 — [Clustering][] (k-means), [Mixture of Gaussians][], [Jensen's
    Inequality][], [Expectation Maximisation][] (EM)
-   13 — Mixture of Gaussians, Mixture of Naive Bayes, [Factor
    Analysis][], and more on Gaussian distributions.
-   14 — Factor Analysis (EM steps), [Principal Component Analysis][]
    (PCA).
-   15 — PCA: [Latent Semantic Indexing][] (LSI), [Singular Value
    Decomposition][] (SVD) algorithm, and [Independent Component
    Analysis][] (ICA).
-   16 — [Markov Decision Process][] (MDPs), Value Function, [Value
    Iteration][], and [Policy Iteration][].
-   17 — Reinforcement learning, using [Markov Decision
    Processes][Markov Decision Process] (MDPs), scaled up to continuous
    variables. Motivating example is controlling an inverted pendulum.
    Models of system to control can either be derived (eg. physics
    model) or learned (eg. via a helicopter pilot)
-   18 — State Action Rewards, Finite Horizon MDPs, Linear Dynamic
    Systems (Models, [Linear Quadratic Regulation][] (LQR), [Riccati
    equation][]).
-   19 — Debugging RL algorithms, LQR (Differential Dynamic Programming
    (DDP)), [Kalman Filters][], [Linear Quadratic Gaussians][] (LQG).
-   20 — [POMDPs][] (Partially Observable MDPs), Policy Search,
    Reinforce, Pegasus, Conclusion.

iTunes University is a great way to keep up to date with a range of
topics. Worth checking out to see what else you can find.

  [Machine Learning]: http://www.stanford.edu/class/cs229/
  [YouTube]: http://www.youtube.com/results?search_query=machine+learning+stanford+%22machine+learning%22&as=1&and_queries=machine+learning+stanford&exact_query=machine+learning&or_queries=&negative_queries=&geo_name=stanford+ca&geo_latlong=&search_duration=&search_hl=&search_category_type=specific&search_category=27&search_sort=&uploaded=
  [iTunes University]: http://deimos3.apple.com/WebObjects/Core.woa/Browse/itunes.stanford.edu.1615003397.01615003400.1607367212?i=1436041694
  [section notes]: http://www.stanford.edu/class/cs229/materials.html
  [Linear regression]: http://en.wikipedia.org/wiki/Linear_regression
  [Gradient Descent]: http://en.wikipedia.org/wiki/Gradient_descent
  [Normal Equations]: http://en.wikipedia.org/wiki/Normal_equations
  [Newton's method]: http://en.wikipedia.org/wiki/Newton%27s_method
  [Perceptron]: http://en.wikipedia.org/wiki/Perceptron
  [Logistic regression]: http://en.wikipedia.org/wiki/Logistic_regression
  [Exponential Family]: http://en.wikipedia.org/wiki/Exponential_family
  [Generalised Linear Models]: http://en.wikipedia.org/wiki/Generalised_linear_model
  [Gaussian Discriminate Analysis]: http://en.wikipedia.org/wiki/Gaussian_discriminant_analysis
  [Naive Bayes]: http://en.wikipedia.org/wiki/Naive_Bayes_classifier
  [Laplace Smoothing]: http://en.wikipedia.org/wiki/Laplace_smoothing
  [Neural Networks]: http://en.wikipedia.org/wiki/Artificial_neural_network
  [Support Vector Machines]: http://en.wikipedia.org/wiki/Support_vector_machine
  [Kernels]: http://en.wikipedia.org/wiki/Kernel_(statistics)
  [Soft Margin]: http://en.wikipedia.org/wiki/Support_vector_machine#Soft_margin
  [Empirical Risk Minimisation]: http://en.wikipedia.org/wiki/Empirical_risk_minimization
  [Hoeffding inequality]: http://en.wikipedia.org/wiki/Hoeffding%27s_inequality
  [Uniform Convergence]: http://en.wikipedia.org/wiki/Uniform_convergence
  [Clustering]: http://en.wikipedia.org/wiki/Cluster_analysis#K-means_and_derivatives
  [Mixture of Gaussians]: http://en.wikipedia.org/wiki/Mixture_of_gaussians
  [Jensen's Inequality]: http://en.wikipedia.org/wiki/Jensen%27s_inequality
  [Expectation Maximisation]: http://en.wikipedia.org/wiki/Expectation-maximization_algorithm
  [Factor Analysis]: http://en.wikipedia.org/wiki/Factor_analysis
  [Principal Component Analysis]: http://en.wikipedia.org/wiki/Principle_components_analysis
  [Latent Semantic Indexing]: http://en.wikipedia.org/wiki/Latent_semantic_indexing
  [Singular Value Decomposition]: http://en.wikipedia.org/wiki/Singular_value_decomposition
  [Independent Component Analysis]: http://en.wikipedia.org/wiki/Independent_component_analysis
  [Markov Decision Process]: http://en.wikipedia.org/wiki/Markov_decision_process
  [Value Iteration]: http://en.wikipedia.org/wiki/Value_iteration#Value_iteration
  [Policy Iteration]: http://en.wikipedia.org/wiki/Value_iteration#Policy_iteration
  [Linear Quadratic Regulation]: http://en.wikipedia.org/wiki/Linear-quadratic_regulator
  [Riccati equation]: http://en.wikipedia.org/wiki/Riccati_equation
  [Kalman Filters]: http://en.wikipedia.org/wiki/Kalman_filter
  [Linear Quadratic Gaussians]: http://en.wikipedia.org/wiki/Linear-quadratic-Gaussian_control
  [POMDPs]: http://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process
